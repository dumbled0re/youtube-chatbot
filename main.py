import json
import math
import os

import streamlit as st
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import YoutubeLoader
from langchain.prompts import (ChatPromptTemplate, HumanMessagePromptTemplate,
                               SystemMessagePromptTemplate)
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from youtube_transcript_api import YouTubeTranscriptApi

load_dotenv()

functions = [
    {
        "name": "generate_video_response",
        "description": "è³ªå•ã‚’æŠ½å‡ºã™ã‚‹",
        "parameters": {
            "type": "object",
            "properties": {
                "question": {
                    "type": "string",
                    "description": "è³ªå•äº‹é … e.g. å‹•ç”»å†…å®¹ã‚’è¦ç´„ã—ã¦",
                },
            },
            "required": ["question"],
        },
    },
    {
        "name": "generate_video_time_response",
        "description": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã™ã‚‹",
        "parameters": {
            "type": "object",
            "properties": {
                "keyword": {
                    "type": "string",
                    "description": "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ e.g. ã€‡ã€‡ã«ã¤ã„ã¦ã€ã€‡ã€‡ã«é–¢ã—ã¦",
                },
            },
            "required": ["keyword"],
        }
    },
    {
        "name": "get_index",
        "description": "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç•ªå·ã‚’æŠ½å‡ºã™ã‚‹",
        "parameters": {
            "type": "object",
            "properties": {
                "index": {
                    "type": "string",
                    "description": "ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç•ªå· e.g. 1ç•ª",
                },
            },
            "required": ["index"],
        }
    },
]


def get_question(llm, question):
    messages = llm.predict_messages(
        [HumanMessage(content=question)],
        functions=functions,
    )

    return messages.additional_kwargs

# TODO: ä»¥ä¸‹ã®get_keywordã¯ã„ã‚‰ãªã„ã®ã§ã¯ï¼Ÿ
def get_keyword(llm, message):
    messages = llm.predict_messages(
        [HumanMessage(content=message)],
        functions=functions,
    )

    return messages.additional_kwargs


def get_index(llm, message):
    messages = llm.predict_messages(
        [HumanMessage(content=message)],
        functions=functions,
    )

    return messages.additional_kwargs


def set_up_page() -> None:
    """
    ãƒšãƒ¼ã‚¸ã®è¨­å®šã¨ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°
    """

    # ãƒšãƒ¼ã‚¸ä¸Šéƒ¨ã®éƒ¨åˆ†ã®è¨­å®š
    st.set_page_config(
        page_title="Youtube Chatbot",
        page_icon="ğŸ¤–",
    )

    # ãƒ˜ãƒƒãƒ€ãƒ¼ã®è¡¨ç¤º
    st.header("Youtube Chatbot ğŸ¤–")


def init_session_state(session_state: dict) -> dict[str, list[str]]:
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã‚’åˆæœŸåŒ–ã™ã‚‹é–¢æ•°

    Args:
        session_state (dict): ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ
    Returns:
        dict: åˆæœŸåŒ–ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ
    """

    if not session_state:
        session_state.messages = [
            SystemMessage(content="You are a helpful assistant.")
        ]

    return session_state


def display_chat_history(messages: list) -> None:
    """ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤ºã™ã‚‹é–¢æ•°

    Args:
        messages (list): ãƒãƒ£ãƒƒãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒªã‚¹ãƒˆ
    """

    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message('assistant'):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message('user'):
                st.markdown(message.content)


def convert_seconds(seconds: int) -> str:
    """ç§’ã‚’åˆ†ã‚„æ™‚é–“ã«æ›ç®—ã™ã‚‹

    Args:
        seconds (int): æ›ç®—å¯¾è±¡ã®ç§’æ•°
    Returns:
        str: æ›ç®—çµæœã®æ•°å€¤ã¾ãŸã¯"æ™‚é–“:åˆ†"ã®æ–‡å­—åˆ—
    """

    minutes = 0
    hours = 0

    if seconds < 60:
        return f"{seconds}ç§’"

    elif seconds < 3600:
        minutes = math.floor(seconds / 60)
        remaining_seconds = seconds % 60
        return f"{minutes}åˆ†{remaining_seconds}ç§’"

    else:
        hours = math.floor(seconds / 3600)
        minutes = math.floor((seconds % 3600) / 60)
        return f"{hours}æ™‚é–“{minutes}åˆ†{seconds % 60}ç§’"


def split_text_by_time_intervals(json_data, split_duration=60) -> dict[str, dict[str, str]]:
    """ä¸ãˆã‚‰ã‚ŒãŸ JSON ãƒ‡ãƒ¼ã‚¿ã‚’æŒ‡å®šã—ãŸæ™‚é–“é–“éš”ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ã—ã€å„ãƒãƒ£ãƒ³ã‚¯ã®æƒ…å ±ã‚’è¿”ã™

    Parameters:
        json_data (list): JSON ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        split_duration (float): åŒºåˆ‡ã‚Šã®ç§’æ•°

    Returns:
        dict: å„ãƒãƒ£ãƒ³ã‚¯ã®æƒ…å ±ã‚’å«ã‚€è¾æ›¸ã€‚ã‚­ãƒ¼ã¯ãƒãƒ£ãƒ³ã‚¯ã®ç•ªå·ã€å€¤ã¯ãƒãƒ£ãƒ³ã‚¯ã®æƒ…å ±ã‚’å«ã‚€è¾æ›¸
    """

    split_texts = list()
    current_text = ""
    current_start = 0
    current_end = split_duration

    for entry in json_data:
        start_time = entry["start"]
        text = entry["text"]

        # ãƒ†ã‚­ã‚¹ãƒˆãŒç¾åœ¨ã®ç¯„å›²å†…ã«åã¾ã£ã¦ã„ã‚‹ã‹ã‚’ç¢ºèª
        if start_time >= current_start + split_duration:
            split_texts.append({"text": current_text.strip(), "start": current_start, "end": current_end})
            current_text = ""
            current_start += split_duration
            current_end += split_duration

        # ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
        current_text += text

    # æœ€å¾Œã®éƒ¨åˆ†ã‚’è¿½åŠ 
    if current_text:
        split_texts.append({"text": current_text.strip(), "start": current_start, "end": current_end})

    chunk_dict = {i: chunk_info for i, chunk_info in enumerate(split_texts)}

    return chunk_dict


def generate_video_response(llm: ChatOpenAI, question: str, content: str) -> str:
    system_template = "ã‚ãªãŸã¯ã€è³ªå•è€…ã‹ã‚‰ã®è³ªå•ã‚’å›ç­”ã™ã‚‹AIã§ã™ã€‚"
    human_template = """
        ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å…ƒã«ã€Œ{question}ã€ã«ã¤ã„ã¦ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

        {document}
    """

    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)
    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
    prompt_message_list = chat_prompt.format_prompt(
        question=question,
        document=content).to_messages()
    response = llm(prompt_message_list)

    return response


def generate_video_time_response(llm: ChatOpenAI, keyword: str, chunk_dict: dict[str, dict]) -> str:
    system_template = "ã‚ãªãŸã¯ã€è³ªå•è€…ã‹ã‚‰ã®è³ªå•ã‚’å›ç­”ã™ã‚‹AIã§ã™ã€‚"
    human_template = """
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}

    jsonãƒ‡ãƒ¼ã‚¿:
    --------------------
    {chunk_dict}
    --------------------

    ä¸Šè¨˜ã®jsonãƒ‡ãƒ¼ã‚¿ã®ä¸­ã‹ã‚‰ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{keyword}ã€ã¨æœ€ã‚‚é–¢é€£æ€§ãŒé«˜ã„textã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ç­”ãˆã¦ãã ã•ã„ã€‚

    å›ç­”ã®å½¢å¼ã¯
    ã€Œ{keyword}ã®èª¬æ˜ã¯{index}ç•ªã§ã™ã€‚ã€
    ã¨ã—ã¦ãã ã•ã„ã€‚
    ã‚‚ã—ã‚‚ã€{keyword}ã®èª¬æ˜ãŒãªã„å ´åˆã¯ã€Œ{keyword}ã®èª¬æ˜ã¯å‹•ç”»å†…ã«ã‚ã‚Šã¾ã›ã‚“ã€‚ã€ã¨ã—ã¦ãã ã•ã„ã€‚
    """

    system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)
    chat_prompt = ChatPromptTemplate.from_messages(
        [system_message_prompt, human_message_prompt])
    prompt_message_list = chat_prompt.format_prompt(
        keyword=keyword,
        chunk_dict=chunk_dict,
        index="ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹").to_messages()
    response = llm(prompt_message_list)

    return response


def main() -> None:
    llm = ChatOpenAI(openai_api_key=os.environ.get("OPENAI_API_KEY"),
                     model_name="gpt-3.5-turbo-16k",
                     temperature=0)
    set_up_page()
    session_state = init_session_state(st.session_state)

    url = st.text_input("Youtube URL: ", key="input")
    if url:
        with st.spinner("Fetching Content ..."):
            loader = YoutubeLoader.from_youtube_url(
                url,
                add_video_info=True,
                language=['ja']
            )
            document = loader.load()
            video_id = document[0].metadata["source"]
            content = document[0].page_content
            transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=["ja"])
            chunk_dict = split_text_by_time_intervals(transcript)

    if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("Chatbot is typing ..."):
            additional_kwargs = get_question(llm, user_input)
            if additional_kwargs:
                if additional_kwargs["function_call"]["name"] == "generate_video_response":
                    question = json.loads(additional_kwargs["function_call"]["arguments"]).get("question")
                    response = generate_video_response(llm, question, content)
                    session_state.messages.append(AIMessage(content=response.content))

                elif additional_kwargs["function_call"]["name"] == "generate_video_time_response":
                    keyword = json.loads(additional_kwargs["function_call"]["arguments"]).get("keyword")
                    response = generate_video_time_response(llm, keyword, chunk_dict)
                    additional_kwargs = get_index(llm, response.content)
                    if additional_kwargs:
                        # TODO: ã“ã“ã§function callingã‚’ä½¿ç”¨ã™ã‚‹ã‹ãŒæ‚©ã¾ã—ã„(third_responseå†…ã«ã¯æ•°å­—ãŒå…¥ã£ã¦ã„ã‚‹ã‘ã©å–å¾—ã—ã¦ã„ãªã„æ™‚ãŒã‚ã‚‹)
                        index = json.loads(additional_kwargs["function_call"]["arguments"]).get("index")
                        if index is not None:
                            start = convert_seconds(chunk_dict[int(index)]["start"])
                            end = convert_seconds(chunk_dict[int(index)]["end"])
                            answer = f"{keyword}ã®èª¬æ˜ã¯å‹•ç”»ã®{start}ã‹ã‚‰{end}ã§ã™ã€‚"
                            session_state.messages.append(AIMessage(content=answer))
                        else:
                            answer = f"ç§ãŒæ€ã†{keyword}ã®èª¬æ˜ã«æœ€ã‚‚é–¢é€£æ€§ãŒé«˜ã„textã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯{index}ç•ªã§ã™ã€‚"
                            session_state.messages.append(AIMessage(content=answer))
                    else:
                        session_state.messages.append(AIMessage(content=response.content))
            else:
                response = llm(session_state.messages)
                session_state.messages.append(AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = session_state.get('messages', [])
    display_chat_history(messages)


if __name__ == '__main__':
    main()
