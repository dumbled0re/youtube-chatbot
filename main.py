import json
import os

import streamlit as st
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI
from langchain.document_loaders import YoutubeLoader
from langchain.prompts import (ChatPromptTemplate, HumanMessagePromptTemplate,
                               SystemMessagePromptTemplate)
from langchain.schema import AIMessage, HumanMessage, SystemMessage

load_dotenv()

functions = [
    {
        "name": "get_question",
        "description": "è³ªå•ã‚’æŠ½å‡ºã™ã‚‹",
        "parameters": {
            "type": "object",
            "properties": {
                "question": {
                    "type": "string",
                    "description": "è³ªå•äº‹é … e.g. è¦ç´„",
                    # "description": "è³ªå•äº‹é …",
                },
            },
            "required": ["question"],
        },
    }
]


def get_question(llm, message):
    chat_completion = llm.predict_messages(
        [HumanMessage(content=message)],
        functions=functions,
    )

    return chat_completion
    # return message.additional_kwargs


def generate_responses_from_video_transcription(llm, message):
    pass


def main():
    llm = ChatOpenAI(openai_api_key=os.environ.get("OPENAI_API_KEY"),
                     model_name="gpt-3.5-turbo-16k",
                     temperature=0)

    # ãƒšãƒ¼ã‚¸ä¸Šéƒ¨ã®éƒ¨åˆ†
    st.set_page_config(
        page_title="Youtube chatbot",
        page_icon="ğŸ¤—"
    )
    st.header("Youtube chatbot ğŸ¤—")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if not st.session_state:
        st.session_state.messages = [
            SystemMessage(content="You are a helpful assistant.")
        ]

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    # if url := st.text_input("Youtube URL: ", key="input"):
    url = st.text_input("Youtube URL: ", key="input")
    print(f"url: {url}")
    if url:
        with st.spinner("Fetching Content ..."):
            loader = YoutubeLoader.from_youtube_url(
                url,
                # add_video_info=True,  # ã‚¿ã‚¤ãƒˆãƒ«ã‚„å†ç”Ÿæ•°ã‚‚å–å¾—ã§ãã‚‹
                language=['ja']
            )
            document = loader.load()
            video_content = document[0].page_content
            print(f"document: {document}\n")
            # print(f"video_content: {video_content}")

    if user_input := st.chat_input("ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("ç”Ÿæˆä¸­..."):
            # response = llm(st.session_state.messages)
            response = get_question(llm, user_input)
            if response.additional_kwargs:
                print(f"response: {response}")
                print(f"response.additional_kwargs: {response.additional_kwargs}")
                question = json.loads(
                    response.additional_kwargs["function_call"]["arguments"]).get("question")
                print(f"question: {question}")

                system_template = "ã‚ãªãŸã¯ã€è³ªå•è€…ã‹ã‚‰ã®è³ªå•ã‚’{language}ã§å›ç­”ã™ã‚‹AIã§ã™ã€‚"
                human_template = """
                    ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å…ƒã«ã€Œ{question}ã€ã«ã¤ã„ã¦ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

                    {document}
                """

                system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)
                human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

                print(f"system_message_prompt: {system_message_prompt}")
                print(f"human_message_prompt: {human_message_prompt}")

                chat_prompt = ChatPromptTemplate.from_messages(
                    [system_message_prompt, human_message_prompt])
                prompt_message_list = chat_prompt.format_prompt(
                    language="æ—¥æœ¬èª",
                    question=question,
                    document=video_content).to_messages()
                second_response = llm(prompt_message_list)
                print(f"second_response: {second_response}")

                st.session_state.messages.append(
                    AIMessage(content=second_response.content))
            else:
                print("function callingãŒå‘¼ã³å‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                response = llm(st.session_state.messages)
                st.session_state.messages.append(
                    AIMessage(content=response.content))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get('messages', [])
    print(f"messages: {messages}")
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message('assistant'):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message('user'):
                st.markdown(message.content)


if __name__ == '__main__':
    main()
